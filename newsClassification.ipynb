{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "newsClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKMrEHHS2ymtnetf8Vovk+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dilanbakr/newsClassification/blob/main/newsClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XMAEk6PLFkI"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZaUCM2XI-3F"
      },
      "source": [
        "data = fetch_20newsgroups()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsb24CDsMLFJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "28d41895-b565-4ab5-a102-3019ffa8833e"
      },
      "source": [
        "data.data[0].strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zUM3E8vK_oX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7aa984de-e31d-43db-9eac-1b0769173b07"
      },
      "source": [
        "print(\"------------ VERI ------------\")\n",
        "print(data.data[0].strip())\n",
        "print(\"\\nLABEL:\", data.target_names[data.target[0]], \"=\", data.target[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ VERI ------------\n",
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "LABEL: rec.autos = 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLec8EXlLXbC"
      },
      "source": [
        "categories = ['comp.graphics', 'sci.space', 'talk.politics.guns',\n",
        "            'rec.autos', 'sci.crypt', 'sci.electronics', 'comp.sys.ibm.pc.hardware']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF7KNr4HOHN9"
      },
      "source": [
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), categories=categories ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k66kLrWPPP_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17d3fe64-16c8-4c1a-b38f-e6c5a000ea9f"
      },
      "source": [
        "newsgroups.target.tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 5,\n",
              " 0,\n",
              " 2,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 1,\n",
              " 3,\n",
              " 6,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 6,\n",
              " 6,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 6,\n",
              " 4,\n",
              " 6,\n",
              " 3,\n",
              " 4,\n",
              " 6,\n",
              " 4,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 5,\n",
              " 1,\n",
              " 4,\n",
              " 2,\n",
              " 6,\n",
              " 1,\n",
              " 4,\n",
              " 0,\n",
              " 6,\n",
              " 6,\n",
              " 4,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 6,\n",
              " 4,\n",
              " 3,\n",
              " 4,\n",
              " 1,\n",
              " 6,\n",
              " 0,\n",
              " 5,\n",
              " 6,\n",
              " 3,\n",
              " 5,\n",
              " 1,\n",
              " 4,\n",
              " 4,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 4,\n",
              " 0,\n",
              " 5,\n",
              " 3,\n",
              " 6,\n",
              " 6,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 5,\n",
              " 1,\n",
              " 1,\n",
              " 5,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 5,\n",
              " 3,\n",
              " 6,\n",
              " 6,\n",
              " 5,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 6,\n",
              " 4,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 2,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 6,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 5,\n",
              " 4,\n",
              " 6,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 4,\n",
              " 6,\n",
              " 4,\n",
              " 3,\n",
              " 6,\n",
              " 4,\n",
              " 4,\n",
              " 0,\n",
              " 2,\n",
              " 4,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 5,\n",
              " 5,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 5,\n",
              " 5,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 5,\n",
              " 2,\n",
              " 4,\n",
              " 0,\n",
              " 6,\n",
              " 1,\n",
              " 3,\n",
              " 4,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 2,\n",
              " 2,\n",
              " 5,\n",
              " 4,\n",
              " 6,\n",
              " 2,\n",
              " 5,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 6,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 4,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 4,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 6,\n",
              " 4,\n",
              " 6,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 4,\n",
              " 5,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 6,\n",
              " 1,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 2,\n",
              " 4,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 0,\n",
              " 6,\n",
              " 6,\n",
              " 6,\n",
              " 6,\n",
              " 4,\n",
              " 1,\n",
              " 5,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 5,\n",
              " 6,\n",
              " 4,\n",
              " 4,\n",
              " 1,\n",
              " 3,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 4,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 6,\n",
              " 6,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 6,\n",
              " 4,\n",
              " 3,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 3,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 6,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 6,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 6,\n",
              " 5,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 4,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 1,\n",
              " 5,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 4,\n",
              " 1,\n",
              " 6,\n",
              " 0,\n",
              " 0,\n",
              " 5,\n",
              " 1,\n",
              " 5,\n",
              " 5,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 6,\n",
              " 1,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 6,\n",
              " 6,\n",
              " 5,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 1,\n",
              " 6,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 6,\n",
              " 3,\n",
              " 6,\n",
              " 4,\n",
              " 6,\n",
              " 6,\n",
              " 1,\n",
              " 0,\n",
              " 4,\n",
              " 4,\n",
              " 6,\n",
              " 0,\n",
              " 3,\n",
              " 5,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 6,\n",
              " 4,\n",
              " 2,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 4,\n",
              " 6,\n",
              " 6,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 4,\n",
              " 6,\n",
              " 5,\n",
              " 3,\n",
              " 2,\n",
              " 5,\n",
              " 5,\n",
              " 2,\n",
              " 6,\n",
              " 0,\n",
              " 2,\n",
              " 5,\n",
              " 6,\n",
              " 3,\n",
              " 5,\n",
              " 1,\n",
              " 5,\n",
              " 6,\n",
              " 6,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 5,\n",
              " 6,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 5,\n",
              " 1,\n",
              " 1,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 4,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 6,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 4,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 6,\n",
              " 6,\n",
              " 3,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 5,\n",
              " 5,\n",
              " 1,\n",
              " 5,\n",
              " 2,\n",
              " 6,\n",
              " 4,\n",
              " 6,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 5,\n",
              " 0,\n",
              " 2,\n",
              " 4,\n",
              " 2,\n",
              " 0,\n",
              " 5,\n",
              " 4,\n",
              " 5,\n",
              " 1,\n",
              " 6,\n",
              " 4,\n",
              " 2,\n",
              " 0,\n",
              " 5,\n",
              " 4,\n",
              " 6,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 3,\n",
              " 5,\n",
              " 0,\n",
              " 4,\n",
              " 0,\n",
              " 2,\n",
              " 6,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 5,\n",
              " 2,\n",
              " 6,\n",
              " 4,\n",
              " 0,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 0,\n",
              " 6,\n",
              " 3,\n",
              " 1,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 6,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 5,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 6,\n",
              " 6,\n",
              " 5,\n",
              " 1,\n",
              " 4,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 4,\n",
              " 3,\n",
              " 5,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 5,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 4,\n",
              " 1,\n",
              " 4,\n",
              " 6,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 6,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 3,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 5,\n",
              " 6,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 4,\n",
              " 0,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 4,\n",
              " 0,\n",
              " 5,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 6,\n",
              " 4,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 4,\n",
              " 1,\n",
              " 3,\n",
              " 6,\n",
              " 2,\n",
              " 5,\n",
              " 2,\n",
              " 6,\n",
              " 4,\n",
              " 0,\n",
              " 3,\n",
              " 6,\n",
              " 4,\n",
              " 6,\n",
              " 1,\n",
              " 5,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 6,\n",
              " 6,\n",
              " 1,\n",
              " 4,\n",
              " 0,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 4,\n",
              " 6,\n",
              " 0,\n",
              " 5,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 4,\n",
              " 4,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 5,\n",
              " 4,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 6,\n",
              " 0,\n",
              " 2,\n",
              " 1,\n",
              " 6,\n",
              " 4,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 5,\n",
              " 3,\n",
              " 6,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 6,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 4,\n",
              " 5,\n",
              " 3,\n",
              " 5,\n",
              " 1,\n",
              " 5,\n",
              " 4,\n",
              " 5,\n",
              " 3,\n",
              " 1,\n",
              " 5,\n",
              " 0,\n",
              " 6,\n",
              " 0,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 5,\n",
              " 2,\n",
              " 6,\n",
              " 1,\n",
              " 2,\n",
              " 6,\n",
              " 5,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 6,\n",
              " 4,\n",
              " 1,\n",
              " 0,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 5,\n",
              " 4,\n",
              " 0,\n",
              " 5,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 5,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 4,\n",
              " 2,\n",
              " 5,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 4,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 6,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 2,\n",
              " 0,\n",
              " 6,\n",
              " 5,\n",
              " 2,\n",
              " 6,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 5,\n",
              " 4,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 5,\n",
              " 1,\n",
              " 1,\n",
              " 6,\n",
              " 1,\n",
              " 4,\n",
              " 0,\n",
              " 5,\n",
              " 1,\n",
              " 4,\n",
              " 4,\n",
              " 1,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 2,\n",
              " 6,\n",
              " 2,\n",
              " 6,\n",
              " 2,\n",
              " 1,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 5,\n",
              " 4,\n",
              " 0,\n",
              " 3,\n",
              " 5,\n",
              " 6,\n",
              " 0,\n",
              " 4,\n",
              " 2,\n",
              " 6,\n",
              " 4,\n",
              " 2,\n",
              " 5,\n",
              " 4,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQQ1zHCMOWuk"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_ = pd.DataFrame([newsgroups.data, newsgroups.target.tolist()]).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiDZnFdtV7pA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "18abf4e5-adfc-4bc2-f7d5-2842baac7819"
      },
      "source": [
        "newsgroups.target_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comp.graphics',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'rec.autos',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.space',\n",
              " 'talk.politics.guns']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JegzocGqRSVB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c792c831-3bf0-470f-e109-c95d6bb4c448"
      },
      "source": [
        "df_.columns = ['text', 'target']\n",
        "targets = pd.DataFrame(newsgroups.target_names)\n",
        "targets.columns=['topic']\n",
        "df = pd.merge(df_, targets, left_on='target', right_index=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have just a few quick questions.  Does anyon...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maybe I should have been clearer.  I have a In...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Anybody use CD Speedway out there?  Is it as g...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Hi,\\n    Can somebody tell me step by step how...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I have a WANGTEK tape controller card (Revisio...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ...                     topic\n",
              "0   I have just a few quick questions.  Does anyon...  ...  comp.sys.ibm.pc.hardware\n",
              "2   Maybe I should have been clearer.  I have a In...  ...  comp.sys.ibm.pc.hardware\n",
              "4   Anybody use CD Speedway out there?  Is it as g...  ...  comp.sys.ibm.pc.hardware\n",
              "9   Hi,\\n    Can somebody tell me step by step how...  ...  comp.sys.ibm.pc.hardware\n",
              "11  I have a WANGTEK tape controller card (Revisio...  ...  comp.sys.ibm.pc.hardware\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjOs9f6oWMHI"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import nltk\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Runeodp6awLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "55b932d9-c08e-4883-8599-0bc9bd392429"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe3ZdPA1iSpY"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mztJA_BZLv2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c009c492-1095-486f-c859-023fff330477"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return \" \".join(result)\n",
        "    \n",
        "processed_docs = df['text'].map(preprocess)\n",
        "df['cleaned_text'] = processed_docs\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>topic</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I have just a few quick questions.  Does anyon...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>quick question cyrix problem second cyric moth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maybe I should have been clearer.  I have a In...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>mayb clearer intel like motherboard local vend...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Anybody use CD Speedway out there?  Is it as g...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>anybodi speedway good hate wait finish load le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Hi,\\n    Can somebody tell me step by step how...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>somebodi tell step step kalok exist maxtor sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I have a WANGTEK tape controller card (Revisio...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>wangtek tape control card revis syto backup ba...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  ...                                       cleaned_text\n",
              "0   I have just a few quick questions.  Does anyon...  ...  quick question cyrix problem second cyric moth...\n",
              "2   Maybe I should have been clearer.  I have a In...  ...  mayb clearer intel like motherboard local vend...\n",
              "4   Anybody use CD Speedway out there?  Is it as g...  ...  anybodi speedway good hate wait finish load le...\n",
              "9   Hi,\\n    Can somebody tell me step by step how...  ...  somebodi tell step step kalok exist maxtor sta...\n",
              "11  I have a WANGTEK tape controller card (Revisio...  ...  wangtek tape control card revis syto backup ba...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Ej6e8ibsWS"
      },
      "source": [
        "max_len = 1000 #1000 kelimeden sonrasını kesecek texte\n",
        "max_words = 2000 ## Nitelik olarak düşünülecek kelime sayısı\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words) # 1000 kelime idin kelime ayırıcı\n",
        "tokenizer.fit_on_texts(df.cleaned_text) #Kelime indekslerini oluşturuyor. \n",
        "sequences = tokenizer.texts_to_sequences(df.cleaned_text)\n",
        "word_index = tokenizer.word_index \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWRgSRKjnXOw"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PCubmPFlH9q"
      },
      "source": [
        "data = pad_sequences(sequences, maxlen=max_len)\n",
        "labels = to_categorical(np.asarray(df.target)) # Sınıf etiketlerinin vektöre dönüştürülmesi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5O9HJlgmMk7"
      },
      "source": [
        "embedding_dim = 100\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Conv1D, MaxPooling1D, Dropout, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A38ClIZwqBQL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "7134903c-249c-451f-e199-17e8e6a6f085"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1, embedding_dim, mask_zero=True, input_length=max_len, trainable=True))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(MaxPooling1D(35))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 1000, 100)         2539000   \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 996, 128)          64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 199, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 199, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 195, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 39, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 35, 128)           82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 1, 128)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 903       \n",
            "=================================================================\n",
            "Total params: 2,784,639\n",
            "Trainable params: 2,784,639\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0_7GHCCxYXS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVuwyiXsuAbR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "3856ecd8-4144-46dc-dbf3-635997859a84"
      },
      "source": [
        "histroy = model.fit(X_train, y_train, epochs=15, batch_size=128, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 1.7444 - acc: 0.2543 - val_loss: 1.5983 - val_acc: 0.3006\n",
            "Epoch 2/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 1.4600 - acc: 0.3540 - val_loss: 1.3700 - val_acc: 0.4091\n",
            "Epoch 3/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 1.2035 - acc: 0.4895 - val_loss: 1.1487 - val_acc: 0.5543\n",
            "Epoch 4/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.9598 - acc: 0.6034 - val_loss: 1.1034 - val_acc: 0.5557\n",
            "Epoch 5/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.7980 - acc: 0.6830 - val_loss: 1.0765 - val_acc: 0.6158\n",
            "Epoch 6/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.6537 - acc: 0.7493 - val_loss: 1.0942 - val_acc: 0.6364\n",
            "Epoch 7/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.5297 - acc: 0.8068 - val_loss: 1.2247 - val_acc: 0.6305\n",
            "Epoch 8/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.4549 - acc: 0.8359 - val_loss: 1.2849 - val_acc: 0.6584\n",
            "Epoch 9/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.4001 - acc: 0.8608 - val_loss: 1.4199 - val_acc: 0.6437\n",
            "Epoch 10/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.3438 - acc: 0.8795 - val_loss: 1.4964 - val_acc: 0.6598\n",
            "Epoch 11/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.2993 - acc: 0.8970 - val_loss: 1.5511 - val_acc: 0.6672\n",
            "Epoch 12/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.2821 - acc: 0.8963 - val_loss: 1.7443 - val_acc: 0.6437\n",
            "Epoch 13/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.2890 - acc: 0.9002 - val_loss: 1.7277 - val_acc: 0.6525\n",
            "Epoch 14/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.2470 - acc: 0.9143 - val_loss: 1.7786 - val_acc: 0.6569\n",
            "Epoch 15/15\n",
            "48/48 [==============================] - 71s 1s/step - loss: 0.2374 - acc: 0.9170 - val_loss: 1.9375 - val_acc: 0.6290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA7jxFMp95RA"
      },
      "source": [
        "score, acc = model2.evaluate(X_test, y_test, batch_size=128)\n",
        "print(\"Test Doğruluğu:', acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR3UaW2w9I7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "238b5ebc-b7f9-4f67-bc18-de3b9d93dc4d"
      },
      "source": [
        "!pip install plot-keras-history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting plot-keras-history\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/5a/8d60eae5d2624877fba35b63b70cea4edcf603c75883c004bb4715470d10/plot_keras_history-1.1.23.tar.gz\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from plot-keras-history) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from plot-keras-history) (1.0.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from plot-keras-history) (1.4.1)\n",
            "Collecting sanitize_ml_labels\n",
            "  Downloading https://files.pythonhosted.org/packages/69/2d/4db7caa3f08982c2ea48f6d6c19079246403a8742c14ea70875f48569dd6/sanitize_ml_labels-1.0.12.tar.gz\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot-keras-history) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot-keras-history) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot-keras-history) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot-keras-history) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->plot-keras-history) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->plot-keras-history) (2018.9)\n",
            "Collecting compress_json\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/9d/1a79dbc3b9d69c57be363b4cc8bd6f278f919a0973f46c7bb831438c9333/compress_json-1.0.4.tar.gz\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->plot-keras-history) (1.15.0)\n",
            "Building wheels for collected packages: plot-keras-history, sanitize-ml-labels, compress-json\n",
            "  Building wheel for plot-keras-history (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plot-keras-history: filename=plot_keras_history-1.1.23-cp36-none-any.whl size=6406 sha256=e532cd3950c8c59f37f44525adb0342708a478cab0b672b8246353c8c026b312\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/78/33/da5ed769fab5587fcdae95271e8d19106e3b92b3ae2d46382d\n",
            "  Building wheel for sanitize-ml-labels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sanitize-ml-labels: filename=sanitize_ml_labels-1.0.12-cp36-none-any.whl size=6596 sha256=751eb10d9a841bca72a5d1f37ae18da28a5644ec74314682aef0eefcffab270c\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/7a/44/401b091c00e8b2e314a474e3f7096d311239d95ff5315e25ab\n",
            "  Building wheel for compress-json (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compress-json: filename=compress_json-1.0.4-cp36-none-any.whl size=4586 sha256=3a1b9a26c8ec3ed624f775b8c5de617f4968ff8f5075b29aefd08fb16f8d6f12\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/ec/21/51460dd508e4a152c0643946c21fae84eb3391171164d35745\n",
            "Successfully built plot-keras-history sanitize-ml-labels compress-json\n",
            "Installing collected packages: compress-json, sanitize-ml-labels, plot-keras-history\n",
            "Successfully installed compress-json-1.0.4 plot-keras-history-1.1.23 sanitize-ml-labels-1.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjnyFa3H85F7"
      },
      "source": [
        "from plot_keras_history import plot_history\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppPNXAOwxFOO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36525454-6a5c-47cc-9e4d-c26db517d939"
      },
      "source": [
        "score, acc = model.evaluate(X_test, y_test, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 2s 280ms/step - loss: 1.9375 - acc: 0.6290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzyw-WoDyCbm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88e99b47-0f73-49e3-cacc-3693fd0a37a7"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6290322542190552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cl_daHWPQTL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bf002e2-a525-4965-f3d3-ea2fed7845d6"
      },
      "source": [
        "y_pred = model.predict(x=X_test)\n",
        "y_pred = y_pred.T[0]\n",
        "y_pred "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.42693460e-01, 1.27458648e-07, 2.08462581e-08, 1.07154074e-05,\n",
              "       1.03908014e-02, 1.88626052e-06, 8.53321850e-01, 2.74755585e-04,\n",
              "       5.94930460e-09, 4.38857824e-03, 4.40535802e-11, 1.31651710e-16,\n",
              "       7.32836640e-03, 9.99640584e-01, 3.72005249e-18, 9.44735482e-02,\n",
              "       3.73335918e-10, 1.48455675e-11, 9.95352983e-01, 2.08248067e-12,\n",
              "       7.24874627e-28, 4.14590062e-07, 9.63780105e-01, 7.38756228e-07,\n",
              "       3.11881304e-03, 4.83787579e-16, 6.84732664e-03, 5.17183589e-03,\n",
              "       2.75800661e-17, 1.11036940e-16, 6.54413431e-27, 2.59330069e-09,\n",
              "       1.96391736e-17, 1.52218314e-18, 7.01011624e-04, 9.87610698e-01,\n",
              "       1.46459345e-15, 7.72502418e-08, 9.99932408e-01, 9.39750976e-07,\n",
              "       3.33286607e-06, 1.92677446e-27, 1.81684259e-03, 1.33863987e-08,\n",
              "       4.59396921e-09, 7.77614332e-06, 3.24240403e-08, 1.52536268e-14,\n",
              "       1.19921551e-05, 3.57373443e-04, 2.72141486e-01, 6.64250422e-07,\n",
              "       4.73500492e-12, 7.98760331e-04, 1.23694641e-04, 1.19466771e-04,\n",
              "       9.79153752e-01, 9.57225683e-22, 5.61363836e-26, 7.95189679e-01,\n",
              "       2.46307841e-09, 1.18713345e-14, 6.15143017e-06, 2.10352873e-26,\n",
              "       2.05609817e-30, 1.84692139e-09, 5.25080530e-08, 3.50931601e-04,\n",
              "       4.37321365e-02, 1.58177107e-04, 6.81383654e-07, 1.48195795e-30,\n",
              "       1.11071028e-08, 3.44218604e-23, 2.97689289e-01, 1.42693460e-01,\n",
              "       1.58611982e-07, 9.92278814e-01, 2.01380230e-03, 6.97210580e-02,\n",
              "       1.08930107e-12, 2.38039779e-11, 6.56856894e-01, 4.64002639e-01,\n",
              "       2.66443100e-03, 1.60495958e-07, 1.50032178e-01, 1.29613967e-03,\n",
              "       3.89502291e-03, 9.95666265e-01, 1.57569548e-15, 8.42383146e-01,\n",
              "       9.57353849e-11, 9.87165451e-01, 8.86258276e-05, 6.76503090e-11,\n",
              "       1.28367290e-01, 2.42986891e-04, 4.23795063e-06, 3.09718013e-01,\n",
              "       1.57417841e-34, 4.87960108e-08, 4.40544663e-30, 2.16610190e-02,\n",
              "       4.15276201e-25, 4.68541543e-08, 2.58515170e-20, 6.09512441e-14,\n",
              "       9.96975780e-01, 3.25345610e-12, 6.96485404e-06, 6.76840007e-17,\n",
              "       5.74126263e-19, 1.75377934e-09, 1.38681813e-03, 1.28882807e-10,\n",
              "       1.10062024e-06, 1.62468132e-16, 1.02869035e-06, 4.44648285e-05,\n",
              "       3.11071559e-22, 2.02623549e-17, 4.28297224e-11, 4.78332957e-19,\n",
              "       2.00477928e-01, 2.10101019e-19, 2.57873274e-02, 5.69244172e-15,\n",
              "       1.70314146e-20, 6.04019195e-14, 3.57436903e-07, 3.15201337e-10,\n",
              "       4.16764345e-27, 6.54915629e-13, 1.07754795e-06, 9.89089787e-01,\n",
              "       5.93086006e-04, 6.42496536e-23, 4.02795066e-13, 1.38936483e-03,\n",
              "       1.07216613e-06, 2.81566956e-19, 7.42966324e-20, 2.39333376e-01,\n",
              "       8.51034150e-02, 4.42572311e-02, 5.22036997e-22, 9.99991059e-01,\n",
              "       9.24740627e-04, 1.47373461e-10, 3.49786660e-15, 2.32147914e-03,\n",
              "       2.83846259e-03, 1.26919575e-09, 2.38073664e-03, 4.70460440e-31,\n",
              "       9.99998331e-01, 1.81147279e-05, 9.37703550e-01, 8.62946868e-01,\n",
              "       5.63571416e-03, 6.76059386e-09, 8.17977430e-31, 2.53887266e-01,\n",
              "       5.92725817e-27, 9.99499679e-01, 4.45066984e-20, 1.05055308e-22,\n",
              "       9.97618973e-01, 8.99246159e-18, 2.68027197e-05, 1.66567497e-06,\n",
              "       1.84014819e-19, 9.99452412e-01, 4.96697965e-07, 8.44552142e-06,\n",
              "       3.46010476e-02, 5.84894568e-24, 1.28216982e-07, 6.34625519e-10,\n",
              "       2.08302647e-01, 7.55031593e-11, 1.04566676e-23, 1.52853066e-34,\n",
              "       2.34944182e-12, 1.85262002e-02, 1.42346725e-01, 1.69623077e-01,\n",
              "       5.74515298e-07, 2.93023169e-01, 6.18715167e-01, 1.50950709e-05,\n",
              "       1.55050242e-02, 1.08365814e-04, 1.42144365e-03, 3.46201404e-07,\n",
              "       8.30377392e-24, 1.72636881e-01, 5.83839999e-09, 1.13371996e-12,\n",
              "       8.04769900e-03, 9.98519361e-01, 5.75351695e-17, 1.01733667e-05,\n",
              "       1.13726424e-11, 2.77845953e-02, 1.49680542e-19, 3.68750703e-24,\n",
              "       1.92170958e-07, 9.57803428e-01, 8.31194731e-24, 5.95144307e-08,\n",
              "       7.53239810e-01, 8.63992870e-01, 2.23265231e-01, 3.49750968e-16,\n",
              "       2.41907928e-02, 2.81653687e-08, 8.82888116e-07, 1.17467344e-03,\n",
              "       1.42693460e-01, 3.22991080e-16, 1.20496519e-01, 3.59582364e-09,\n",
              "       1.44747636e-09, 1.06521896e-20, 2.89425602e-14, 3.15334164e-02,\n",
              "       2.47281823e-13, 3.65998664e-21, 9.50700781e-13, 9.87613559e-01,\n",
              "       7.90312826e-15, 9.90836382e-01, 2.70428673e-15, 7.07052824e-14,\n",
              "       8.71385256e-11, 9.96853888e-01, 4.42627189e-20, 9.27141088e-16,\n",
              "       1.55206680e-01, 6.04401901e-02, 2.89713781e-10, 1.78639468e-07,\n",
              "       1.42693460e-01, 5.90921749e-17, 9.99999762e-01, 1.49304777e-01,\n",
              "       1.85057915e-13, 5.75834314e-08, 9.80242112e-05, 3.11592695e-15,\n",
              "       4.62146878e-01, 1.95415337e-10, 8.82607873e-24, 3.53196375e-02,\n",
              "       5.32223469e-24, 5.57253410e-10, 1.86293728e-05, 6.72254407e-14,\n",
              "       6.35068445e-03, 1.21965451e-04, 4.85221130e-13, 2.52086068e-07,\n",
              "       4.05771196e-01, 2.64801240e-15, 4.78521950e-04, 3.04676954e-20,\n",
              "       1.12385817e-01, 1.19862245e-10, 1.65675385e-18, 9.80199315e-03,\n",
              "       1.90518551e-06, 2.61094500e-24, 5.22117674e-08, 2.95803789e-15,\n",
              "       2.04107836e-30, 1.54000536e-05, 1.60725194e-03, 7.09553510e-02,\n",
              "       4.61355259e-04, 4.18404433e-20, 3.20677304e-06, 8.33780257e-17,\n",
              "       1.60657029e-04, 2.02382267e-07, 1.05260392e-06, 1.92499295e-01,\n",
              "       1.74818770e-03, 3.47855818e-17, 4.21978910e-07, 2.59802194e-17,\n",
              "       2.84918510e-19, 5.35280821e-20, 9.97524694e-08, 9.87738022e-05,\n",
              "       2.38659765e-16, 1.42693460e-01, 1.17823165e-02, 8.78134519e-02,\n",
              "       1.42693460e-01, 8.29186756e-05, 4.36057235e-09, 7.63555169e-02,\n",
              "       1.12277128e-07, 2.30851640e-08, 6.23363690e-08, 5.76047927e-26,\n",
              "       1.37513439e-19, 3.53557158e-22, 2.45499674e-08, 3.43567096e-02,\n",
              "       1.47747374e-25, 9.91124332e-01, 0.00000000e+00, 9.29637594e-08,\n",
              "       2.26436486e-03, 2.45921193e-14, 9.01253396e-18, 6.51336304e-05,\n",
              "       7.70592868e-01, 1.19184131e-06, 7.74524743e-17, 4.34365760e-13,\n",
              "       9.99571145e-01, 4.21191519e-27, 1.83052616e-04, 7.57158946e-22,\n",
              "       9.87565906e-31, 3.67300453e-23, 6.40117196e-06, 5.90468792e-20,\n",
              "       3.15064900e-02, 2.83157783e-06, 5.79915499e-12, 2.78202772e-01,\n",
              "       6.73969150e-01, 1.42693460e-01, 2.97657316e-05, 3.86211500e-23,\n",
              "       3.42423843e-14, 3.32291762e-04, 1.43694706e-16, 8.56816322e-02,\n",
              "       4.30065773e-20, 9.99511719e-01, 9.99999046e-01, 5.19572558e-17,\n",
              "       1.94442626e-22, 2.38948189e-07, 1.86704040e-01, 1.17530439e-08,\n",
              "       1.68323027e-08, 2.88365134e-34, 9.75135267e-01, 1.19251959e-01,\n",
              "       1.07141126e-24, 1.95765307e-19, 1.08534004e-09, 7.30311644e-13,\n",
              "       1.96710026e-13, 2.09602229e-02, 9.99650002e-01, 6.34284131e-03,\n",
              "       1.42693460e-01, 3.10054926e-25, 9.23258106e-13, 1.42693460e-01,\n",
              "       9.97522771e-01, 9.93308425e-01, 4.30424027e-02, 8.72848560e-13,\n",
              "       1.17676898e-16, 1.25861824e-01, 7.58678986e-09, 9.99399662e-01,\n",
              "       6.20796222e-22, 5.15666692e-08, 1.42693460e-01, 9.99999881e-01,\n",
              "       9.99899983e-01, 2.34497993e-36, 7.09692314e-02, 4.01447266e-02,\n",
              "       1.97066858e-01, 2.01740697e-01, 1.25375077e-01, 8.15725161e-06,\n",
              "       1.80880903e-04, 2.27201556e-11, 8.90002761e-04, 1.56785853e-13,\n",
              "       1.32754713e-03, 3.68224711e-13, 9.97992039e-01, 4.04982572e-23,\n",
              "       5.76942803e-05, 6.15778936e-06, 6.86494343e-04, 1.32714855e-02,\n",
              "       4.56983116e-06, 1.50277110e-05, 2.59478550e-23, 7.73295984e-02,\n",
              "       1.56874012e-03, 3.15941378e-07, 1.96115330e-01, 2.20312063e-06,\n",
              "       7.65012214e-22, 1.42693460e-01, 1.97872023e-21, 9.99996066e-01,\n",
              "       2.62691534e-13, 1.77661207e-07, 3.27826207e-22, 2.18198140e-04,\n",
              "       9.78495642e-37, 3.77818196e-06, 1.42693460e-01, 9.51473737e-07,\n",
              "       3.63601968e-02, 1.69534818e-04, 1.88100904e-01, 2.00343947e-03,\n",
              "       1.26905134e-03, 1.00097835e-01, 1.39713043e-13, 1.09266242e-19,\n",
              "       2.53931241e-21, 2.26620356e-17, 6.47601426e-01, 8.96813034e-28,\n",
              "       4.04709488e-01, 7.14540079e-07, 9.76907730e-01, 7.86350084e-14,\n",
              "       3.67639963e-09, 1.00000000e+00, 1.51858523e-14, 1.44675575e-23,\n",
              "       9.99869704e-01, 2.46663934e-09, 5.08461383e-13, 3.01941750e-23,\n",
              "       9.99619722e-01, 3.52528447e-20, 2.23599613e-07, 5.06611941e-05,\n",
              "       1.42693460e-01, 2.90720536e-30, 1.42693460e-01, 3.59304053e-09,\n",
              "       8.91876161e-01, 2.50628415e-21, 1.24155235e-06, 5.90214411e-17,\n",
              "       5.55495426e-05, 9.95862599e-14, 9.41027582e-01, 1.42693460e-01,\n",
              "       1.76800781e-14, 3.12054511e-02, 5.72413919e-05, 1.38615798e-02,\n",
              "       1.21992175e-17, 2.79219648e-06, 2.60649968e-22, 3.63568624e-31,\n",
              "       6.17637167e-25, 9.47139084e-01, 9.47715402e-01, 1.42693460e-01,\n",
              "       2.32436843e-08, 2.28405065e-06, 9.64157039e-07, 2.19269524e-12,\n",
              "       2.53132953e-07, 1.09219027e-05, 4.59736306e-03, 3.69053828e-06,\n",
              "       2.06043610e-16, 2.79425585e-05, 9.51329887e-01, 1.70189626e-11,\n",
              "       2.61828479e-08, 1.06814125e-23, 4.26904649e-01, 9.55386554e-07,\n",
              "       9.99997377e-01, 1.80916081e-20, 2.39251222e-06, 3.39310900e-05,\n",
              "       5.47465449e-03, 9.06941403e-28, 3.35640070e-04, 2.34289701e-06,\n",
              "       8.79438221e-02, 1.62568893e-02, 2.29175930e-06, 4.11237292e-02,\n",
              "       1.12557190e-03, 1.65100329e-26, 1.79377962e-18, 1.42693460e-01,\n",
              "       1.00990704e-07, 1.87929750e-12, 9.99641180e-01, 9.42989668e-15,\n",
              "       3.74045817e-06, 1.77293035e-13, 7.11987546e-23, 3.47188234e-13,\n",
              "       9.99966860e-01, 1.09451686e-22, 9.89433467e-01, 8.10357655e-22,\n",
              "       4.36696339e-30, 1.76831031e-06, 6.99965867e-12, 3.69752252e-06,\n",
              "       9.74971056e-01, 2.82961037e-06, 2.36929211e-22, 1.65693319e-13,\n",
              "       8.21792662e-01, 1.64784968e-01, 9.68271706e-07, 3.92438110e-10,\n",
              "       6.79226398e-01, 6.21977821e-03, 7.83138539e-18, 1.66441065e-08,\n",
              "       8.03635716e-02, 9.07023311e-01, 1.37419431e-09, 3.52057104e-05,\n",
              "       6.82261661e-02, 4.35491570e-24, 1.96124847e-06, 2.20113043e-06,\n",
              "       1.57292467e-04, 9.99991298e-01, 1.38551863e-18, 2.41718697e-03,\n",
              "       5.48056014e-05, 3.84374701e-08, 8.83157790e-01, 1.42693460e-01,\n",
              "       4.10198947e-14, 5.74729289e-04, 2.20948219e-04, 1.42693460e-01,\n",
              "       1.37916908e-01, 2.16718572e-08, 1.89072356e-01, 3.35624143e-02,\n",
              "       3.81671543e-06, 1.15969044e-06, 2.14314908e-01, 7.14376780e-10,\n",
              "       3.08741275e-02, 9.99999642e-01, 1.20396383e-01, 9.99999523e-01,\n",
              "       6.72169376e-10, 1.66147176e-04, 1.73295921e-15, 1.33055584e-08,\n",
              "       1.42769471e-01, 4.48009998e-01, 1.36387186e-07, 9.84976888e-01,\n",
              "       1.63137391e-02, 3.47788751e-01, 5.28598810e-19, 1.22417086e-21,\n",
              "       1.55490690e-11, 1.94729920e-13, 4.18112431e-05, 1.90823572e-04,\n",
              "       5.69629208e-07, 1.42693460e-01, 9.39303431e-13, 1.15868880e-03,\n",
              "       1.22479323e-04, 1.63694720e-12, 9.89539112e-05, 3.36883927e-32,\n",
              "       6.42150430e-11, 2.97498766e-15, 1.42794296e-01, 9.88872826e-01,\n",
              "       4.04542880e-05, 9.42965329e-01, 3.37822272e-13, 8.19354391e-05,\n",
              "       1.42693460e-01, 7.56362278e-05, 1.81534716e-07, 3.25461514e-02,\n",
              "       1.20191785e-07, 1.90725163e-01, 7.28624940e-01, 2.35963924e-08,\n",
              "       7.61482511e-07, 5.44290841e-02, 9.99998569e-01, 5.47611307e-05,\n",
              "       1.91709697e-01, 2.87779331e-01, 2.94159044e-08, 5.03433985e-05,\n",
              "       6.63466677e-12, 6.75343756e-07, 5.51604762e-09, 5.71458719e-17,\n",
              "       9.31668401e-01, 9.70165730e-01, 4.90688379e-08, 2.34163244e-11,\n",
              "       8.57183569e-09, 5.31901717e-01, 1.41476631e-01, 1.51828680e-12,\n",
              "       3.77321757e-10, 9.74809285e-04, 4.68715988e-02, 9.99983549e-01,\n",
              "       7.29844964e-04, 4.34584591e-11, 3.24458063e-01, 2.85190076e-08,\n",
              "       1.79368231e-09, 3.04178754e-03, 2.06744857e-03, 1.29225612e-07,\n",
              "       8.07915092e-01, 4.83683507e-05, 2.70579676e-05, 1.76855407e-04,\n",
              "       1.11072689e-01, 1.17435142e-19, 1.41719986e-11, 2.29552006e-15,\n",
              "       2.52350801e-05, 6.70525372e-01, 1.03379436e-01, 1.19806994e-02,\n",
              "       1.68084551e-03, 8.79476685e-03, 5.46211541e-01, 1.10722717e-13,\n",
              "       1.42693460e-01, 2.12728442e-03, 7.71502187e-08, 1.09029796e-09,\n",
              "       1.33153389e-06, 5.74275455e-25, 1.49149865e-28, 1.61006001e-13,\n",
              "       1.91632196e-01, 1.81022704e-01, 2.21738063e-07, 3.54655202e-23,\n",
              "       1.42693460e-01, 1.13687353e-08, 3.94279609e-17, 1.60222684e-04,\n",
              "       4.37203398e-11, 1.03588297e-06, 8.07987917e-08, 9.99983549e-01,\n",
              "       4.49826757e-06, 1.00000000e+00, 9.99592721e-01, 2.83770591e-01,\n",
              "       1.43636867e-01, 1.53033376e-01, 4.71070613e-04, 3.01661261e-04,\n",
              "       1.85040681e-11, 1.24679818e-05], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL46VI4pUBMm"
      },
      "source": [
        "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])\n",
        "cls_true = np.array(y_test[0:1000])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Tlzdmv_xR_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a75e4da-eca8-4f4e-d1a0-79360237b235"
      },
      "source": [
        "text = [\"If the labor market data continue to hold, if we don’t see a big destruction to consumer spending on the back of the loss of the unemployment benefits, that reduces the sense of urgency that something needs to be done prior to the election,” said Michelle Meyer, head of U.S. economics for Bank of America.\"]\n",
        "#a = np.array(text)\n",
        "tokens = tokenizer.texts_to_sequences(text)\n",
        "tokens_pad = pad_sequences(tokens, maxlen=max_len)\n",
        "tokens_pad.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V-0MI1O_K_R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "acd8aea0-00e4-4bdb-91da-9937387be307"
      },
      "source": [
        "model.predict(tokens_pad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.6158551e-06, 3.2804615e-09, 2.0307170e-05, 9.7520454e-03,\n",
              "        2.3289026e-06, 2.7856217e-03, 9.8743802e-01]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul_ibAicAZxS"
      },
      "source": [
        "tokens_pad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np1rekQxCSal"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}